{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title Markdown Knowledge Base Builder v4.7 (Diagnostic & Hardened)\n",
        "# @markdown This version adds enhanced diagnostic logging and more specific error handling\n",
        "# @markdown to resolve potential conflicts and provide clearer feedback on failures.\n",
        "\n",
        "# @markdown ### 1. Setup\n",
        "# @markdown - Place your .md files into the `DOCUMENT_DIRECTORY` specified below.\n",
        "# @markdown - Ensure your `GOOGLE_API_KEY` is correctly saved in Colab Secrets.\n",
        "\n",
        "# =============================================================================\n",
        "# 1. INSTALLATION\n",
        "# =============================================================================\n",
        "!pip install tqdm pandas google-generativeai -q\n",
        "\n",
        "import os\n",
        "import json\n",
        "import textwrap\n",
        "import time\n",
        "import hashlib\n",
        "from datetime import datetime\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import sqlite3\n",
        "import shutil\n",
        "import threading\n",
        "import sys\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata, drive, auth\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "from google.api_core import exceptions as google_exceptions\n",
        "from urllib3.exceptions import ProtocolError\n",
        "\n",
        "\n",
        "print(\"--- Markdown Knowledge Base Builder v4.7 ---\")\n",
        "\n",
        "# Mount Google Drive at the beginning\n",
        "try:\n",
        "    if not os.path.exists('/content/drive'):\n",
        "        drive.mount('/content/drive', force_remount=True)\n",
        "        print(\"‚úÖ Google Drive mounted successfully.\")\n",
        "    else:\n",
        "        print(\"‚úÖ Google Drive is already mounted.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå CRITICAL ERROR: Google Drive mount failed: {e}\")\n",
        "    print(\"Please ensure you have given this notebook permission to access your Google Drive.\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 2. CONFIGURATION - TUNED FOR RELIABILITY\n",
        "# =============================================================================\n",
        "DOCUMENT_DIRECTORY = '/content/drive/MyDrive/Documents/markdown'\n",
        "OUTPUT_DIRECTORY = '/content/drive/MyDrive/Documents/analyzed_markdown'\n",
        "QUARANTINE_DIRECTORY = os.path.join(OUTPUT_DIRECTORY, '_quarantine')\n",
        "DB_FILE = os.path.join(OUTPUT_DIRECTORY, 'knowledge_base_md.sqlite')\n",
        "\n",
        "MAX_GEMINI_RETRIES = 8\n",
        "GEMINI_RETRY_DELAY = 10\n",
        "MAX_WORKERS = 3\n",
        "SUPPORTED_EXTENSIONS = ['.md']\n",
        "MAX_SPLIT_SIZE_MB = 9\n",
        "\n",
        "# =============================================================================\n",
        "# 3. DATABASE FUNCTIONS (No changes needed)\n",
        "# =============================================================================\n",
        "def init_database():\n",
        "    with sqlite3.connect(DB_FILE) as conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS documents (\n",
        "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                filename TEXT NOT NULL,\n",
        "                file_hash TEXT NOT NULL,\n",
        "                analysis_json TEXT NOT NULL,\n",
        "                processed_at TEXT NOT NULL,\n",
        "                UNIQUE(filename, file_hash)\n",
        "            )\n",
        "        ''')\n",
        "        conn.commit()\n",
        "\n",
        "def add_to_database(filename, file_hash, analysis_result):\n",
        "    with sqlite3.connect(DB_FILE) as conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\n",
        "            \"INSERT OR REPLACE INTO documents (filename, file_hash, analysis_json, processed_at) VALUES (?, ?, ?, ?)\",\n",
        "            (filename, file_hash, json.dumps(analysis_result), analysis_result['processedAt'])\n",
        "        )\n",
        "        conn.commit()\n",
        "\n",
        "def is_file_in_database(filename, file_hash):\n",
        "    with sqlite3.connect(DB_FILE) as conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT 1 FROM documents WHERE filename = ? AND file_hash = ?\", (filename, file_hash))\n",
        "        return cursor.fetchone() is not None\n",
        "\n",
        "def get_all_from_database():\n",
        "    with sqlite3.connect(DB_FILE) as conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT analysis_json FROM documents\")\n",
        "        return [json.loads(row[0]) for row in cursor.fetchall()]\n",
        "\n",
        "def get_last_n_filenames(n=5):\n",
        "    with sqlite3.connect(DB_FILE) as conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT filename FROM documents ORDER BY id DESC LIMIT ?\", (n,))\n",
        "        return [row[0] for row in cursor.fetchall()]\n",
        "\n",
        "# =============================================================================\n",
        "# 4. CORE HELPER FUNCTIONS\n",
        "# =============================================================================\n",
        "def get_file_hash(filepath):\n",
        "    hasher = hashlib.md5()\n",
        "    try:\n",
        "        with open(filepath, 'rb') as f:\n",
        "            while chunk := f.read(8192): hasher.update(chunk)\n",
        "        return hasher.hexdigest()\n",
        "    except Exception: return None\n",
        "\n",
        "def get_file_content_as_text(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            return f.read()\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def find_supported_files_recursive(directory):\n",
        "    print(f\"\\n--- Scanning for {', '.join(SUPPORTED_EXTENSIONS)} files recursively... ---\")\n",
        "    found_files = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        sanitized_root = root.encode(sys.stdout.encoding, errors='replace').decode(sys.stdout.encoding)\n",
        "        print(f\"  -> Scanning directory: {sanitized_root}\", end='\\r')\n",
        "        for file in files:\n",
        "            if os.path.splitext(file)[1].lower() in SUPPORTED_EXTENSIONS:\n",
        "                found_files.append(os.path.join(root, file))\n",
        "    sys.stdout.write(\"\\n\\033[K\")\n",
        "    print(f\"Scan complete. Found {len(found_files)} total supported files.\")\n",
        "    return sorted(found_files)\n",
        "\n",
        "def analyze_with_gemini_with_retries(prompt, filename, model):\n",
        "    current_delay = GEMINI_RETRY_DELAY\n",
        "    for attempt in range(MAX_GEMINI_RETRIES):\n",
        "        try:\n",
        "            response = model.generate_content(prompt, request_options={'timeout': 600})\n",
        "            cleaned_response = response.text.strip()\n",
        "            if cleaned_response.startswith('```json'):\n",
        "                cleaned_response = cleaned_response[7:-3].strip()\n",
        "            if not cleaned_response:\n",
        "                return None\n",
        "            return json.loads(cleaned_response)\n",
        "        except (google_exceptions.ServiceUnavailable, google_exceptions.ResourceExhausted, ProtocolError) as e:\n",
        "            if attempt < MAX_GEMINI_RETRIES - 1:\n",
        "                print(f\"  -> [WARN] Retriable API error for '{filename}' (Attempt {attempt + 1}/{MAX_GEMINI_RETRIES}). Retrying in {current_delay}s. Error: {type(e).__name__}\")\n",
        "                time.sleep(current_delay)\n",
        "                current_delay *= 1.5\n",
        "            else:\n",
        "                print(f\"  -> [ERROR] API call for '{filename}' failed after {MAX_GEMINI_RETRIES} attempts due to persistent API issues.\")\n",
        "                return None\n",
        "        except Exception as e:\n",
        "            print(f\"  -> [ERROR] A non-retriable error occurred for '{filename}' during API call or JSON parsing: {e}\")\n",
        "            return None\n",
        "\n",
        "# =============================================================================\n",
        "# 5. MAIN PROCESSING LOGIC\n",
        "# =============================================================================\n",
        "def create_archival_prompt(doc_text_snippet, filename, knowledge_summary):\n",
        "    prompt = textwrap.dedent(f\"\"\"\n",
        "        You are an expert archivist AI. Analyze the document text provided below and create a structured record for a knowledge base.\n",
        "        Provide ONLY a valid JSON response. If information for a field is not available in the document, state \"Information not available in document\".\n",
        "\n",
        "        DOCUMENT FILENAME: {filename}\n",
        "        CONTEXT OF PREVIOUSLY PROCESSED FILES: {knowledge_summary or \"First document in series.\"}\n",
        "\n",
        "        DOCUMENT TEXT SNIPPET:\n",
        "        ---\n",
        "        {doc_text_snippet}\n",
        "        ---\n",
        "\n",
        "        Required JSON Output (Based on standard archival principles):\n",
        "        {{\n",
        "          \"fileName\": \"{filename}\",\n",
        "          \"fileType\": \"{os.path.splitext(filename)[1]}\",\n",
        "          \"provenance\": \"Who created this file? For what purpose?\",\n",
        "          \"originalOrder\": \"How is the document structured or organized?\",\n",
        "          \"primaryValue\": \"What immediate administrative, fiscal, or legal purpose does it serve?\",\n",
        "          \"secondaryValue\": \"What evidential or informational value does it hold for future research?\",\n",
        "          \"significance\": \"Does it document key decisions, events, or perspectives?\",\n",
        "          \"uniqueness\": \"Is the information available elsewhere or is it unique to this document?\",\n",
        "          \"usability\": \"Is the file well-organized, readable, and accessible?\",\n",
        "          \"context\": \"How does it connect to the other files mentioned in the CONTEXT section?\",\n",
        "          \"intrinsicValue\": \"Does the file‚Äôs original form add value beyond its text content (e.e., unique layout, annotations)?\",\n",
        "          \"summary\": \"Provide a concise one-paragraph summary of the document's core content.\"\n",
        "        }}\n",
        "    \"\"\")\n",
        "    return prompt\n",
        "\n",
        "def process_document(file_path, model):\n",
        "    filename = os.path.basename(file_path)\n",
        "    print(f\"  -> [Thread] Starting analysis for: {filename}...\")\n",
        "    try:\n",
        "        document_text = get_file_content_as_text(file_path)\n",
        "        if not document_text: return None, \"Failed to extract text\"\n",
        "\n",
        "        max_chars = 15000\n",
        "        snippet = document_text[:max_chars] + (\"\\n[...]\" if len(document_text) > max_chars else \"\")\n",
        "\n",
        "        last_files = get_last_n_filenames(5)\n",
        "        knowledge_summary = \"; \".join(last_files)\n",
        "\n",
        "        prompt = create_archival_prompt(snippet, filename, knowledge_summary)\n",
        "        analysis_result = analyze_with_gemini_with_retries(prompt, filename, model)\n",
        "\n",
        "        if not analysis_result:\n",
        "            return None, \"Gemini analysis failed or returned empty\"\n",
        "\n",
        "        # NEW: Diagnostic print\n",
        "        print(f\"  -> [Thread] Successfully received Gemini analysis for: {filename}\")\n",
        "\n",
        "        analysis_result['rawText'] = document_text\n",
        "        analysis_result['filePath'] = file_path\n",
        "        analysis_result['processedAt'] = datetime.now().isoformat()\n",
        "        return analysis_result, \"Success\"\n",
        "    except Exception as exc:\n",
        "        # NEW: This will catch any unexpected errors during the processing of a single file\n",
        "        print(f\"  -> [CRITICAL] An unexpected error occurred while processing {filename}: {exc}\")\n",
        "        return None, f\"Unexpected error: {exc}\"\n",
        "\n",
        "\n",
        "def heartbeat(stop_event, pbar):\n",
        "    while not stop_event.is_set():\n",
        "        time.sleep(60)\n",
        "        if stop_event.is_set():\n",
        "            break\n",
        "        progress = f\"{pbar.n}/{pbar.total} files completed.\" if pbar.total > 0 else \"waiting for files to process.\"\n",
        "        print(f\"\\n‚ù§Ô∏è  [Heartbeat at {datetime.now().strftime('%H:%M:%S')}] Analysis is in progress... {progress}\\n\")\n",
        "\n",
        "\n",
        "def generate_html_report(report_data, version):\n",
        "    df = pd.DataFrame(report_data).reindex(columns=['File', 'Status', 'Details'])\n",
        "    html = df.to_html(index=False, justify='left', border=0, classes='table table-striped')\n",
        "    html_template = f\"\"\"\n",
        "    <html><head><title>Processing Report</title><style>\n",
        "        body {{ font-family: sans-serif; margin: 2em; background-color: #f9f9f9; color: #333; }}\n",
        "        h1 {{ color: #1a1a1a; }} table {{ width: 100%; border-collapse: collapse; box-shadow: 0 2px 3px rgba(0,0,0,0.1); }}\n",
        "        th, td {{ padding: 12px 15px; text-align: left; border-bottom: 1px solid #ddd; }}\n",
        "        th {{ background-color: #4CAF50; color: white; }} tr:nth-child(even) {{ background-color: #f2f2f2; }}\n",
        "    </style></head><body>\n",
        "        <h1>Knowledge Base Processing Report (Version: {version})</h1>\n",
        "        <p><strong>Generated on:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>{html}\n",
        "    </body></html>\"\"\"\n",
        "    report_path = os.path.join(OUTPUT_DIRECTORY, f'_report_v{version}.html')\n",
        "    with open(report_path, 'w') as f: f.write(html_template)\n",
        "    print(f\"üìÑ HTML report saved to: {report_path}\")\n",
        "\n",
        "def main():\n",
        "    print(\"\\nüöÄ Starting Archival Knowledge Base Generation\")\n",
        "    try:\n",
        "        print(\"--- Verifying Google API Key ---\")\n",
        "        API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "        if not API_KEY:\n",
        "            print(\"\\n‚ùå CRITICAL ERROR: 'GOOGLE_API_KEY' not found in Colab Secrets.\")\n",
        "            return\n",
        "        print(\"‚úÖ GOOGLE_API_KEY loaded successfully.\")\n",
        "        genai.configure(api_key=API_KEY)\n",
        "\n",
        "\n",
        "        for dir_path in [OUTPUT_DIRECTORY, QUARANTINE_DIRECTORY]:\n",
        "            if not os.path.exists(dir_path): os.makedirs(dir_path)\n",
        "\n",
        "        auth.authenticate_user()\n",
        "        model = genai.GenerativeModel('gemini-2.5-flash-preview-05-20')\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Critical setup error: {e}\"); return\n",
        "\n",
        "    init_database()\n",
        "    all_files = find_supported_files_recursive(DOCUMENT_DIRECTORY)\n",
        "    session_report, files_to_process = [], []\n",
        "\n",
        "    print(\"\\n--- Checking files against database cache... ---\")\n",
        "    for fp in tqdm(all_files, desc=\"Verifying Files\"):\n",
        "        filename, file_hash = os.path.basename(fp), get_file_hash(fp)\n",
        "        if not file_hash or is_file_in_database(filename, file_hash):\n",
        "            session_report.append({\"File\": filename, \"Status\": \"Skipped\", \"Details\": \"Already processed\"})\n",
        "            continue\n",
        "        files_to_process.append(fp)\n",
        "\n",
        "    print(f\"\\nFound {len(files_to_process)} new or modified files to process.\")\n",
        "\n",
        "    version = datetime.now().strftime('%Y%m%d%H%M%S')\n",
        "    print(f\"\\n--- Starting processing for version: {version} ---\")\n",
        "\n",
        "    if files_to_process:\n",
        "        stop_heartbeat = threading.Event()\n",
        "        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "            pbar = tqdm(total=len(files_to_process), desc=\"Analyzing Documents\")\n",
        "            heartbeat_thread = threading.Thread(target=heartbeat, args=(stop_heartbeat, pbar))\n",
        "            heartbeat_thread.start()\n",
        "\n",
        "            future_to_file = {executor.submit(process_document, filepath, model): filepath for filepath in files_to_process}\n",
        "\n",
        "            try:\n",
        "                for future in as_completed(future_to_file):\n",
        "                    filepath = future_to_file[future]\n",
        "                    filename = os.path.basename(filepath)\n",
        "                    try:\n",
        "                        result, status = future.result()\n",
        "                        if result:\n",
        "                            file_hash = get_file_hash(filepath)\n",
        "                            add_to_database(filename, file_hash, result)\n",
        "                            session_report.append({\"File\": filename, \"Status\": \"Success\", \"Details\": \"Added to database\"})\n",
        "                        else: raise Exception(status)\n",
        "                    except Exception as exc:\n",
        "                        session_report.append({\"File\": filename, \"Status\": \"Failed\", \"Details\": str(exc)})\n",
        "                        shutil.move(filepath, os.path.join(QUARANTINE_DIRECTORY, filename))\n",
        "                    pbar.update(1)\n",
        "            finally:\n",
        "                pbar.close()\n",
        "                stop_heartbeat.set()\n",
        "                heartbeat_thread.join()\n",
        "\n",
        "    print(\"\\n--- Finalizing Knowledge Base ---\")\n",
        "    knowledge_base = get_all_from_database()\n",
        "    final_save_path = os.path.join(OUTPUT_DIRECTORY, f'md_knowledge_base_v{version}.json')\n",
        "    with open(final_save_path, 'w') as f: json.dump(knowledge_base, f, indent=2)\n",
        "\n",
        "    print(f\"\\nüéâ KNOWLEDGE BASE COMPLETE! üéâ\")\n",
        "    print(f\"üß† Total documents in knowledge base: {len(knowledge_base)}\")\n",
        "    print(f\"‚úÖ Final knowledge base saved to: {final_save_path}\")\n",
        "\n",
        "    if os.path.exists(final_save_path) and os.path.getsize(final_save_path) > MAX_SPLIT_SIZE_MB * 1024 * 1024:\n",
        "        print(f\"\\n--- Splitting Knowledge Base (Max size: {MAX_SPLIT_SIZE_MB}MB) ---\")\n",
        "        with open(final_save_path, 'r') as f: full_data = json.load(f)\n",
        "        part_num, current_chunk, current_size = 1, [], 0\n",
        "        for item in full_data:\n",
        "            item_str = json.dumps(item)\n",
        "            item_size = len(item_str.encode('utf-8'))\n",
        "            if current_size + item_size > MAX_SPLIT_SIZE_MB * 1024 * 1024 and current_chunk:\n",
        "                part_path = os.path.join(OUTPUT_DIRECTORY, f'md_knowledge_base_v{version}_part_{part_num}.json')\n",
        "                with open(part_path, 'w') as f: json.dump(current_chunk, f, indent=2)\n",
        "                print(f\"‚úÖ Created part {part_num}: {part_path}\")\n",
        "                part_num += 1\n",
        "                current_chunk, current_size = [item], item_size\n",
        "            else:\n",
        "                current_chunk.append(item)\n",
        "                current_size += item_size\n",
        "        if current_chunk:\n",
        "            part_path = os.path.join(OUTPUT_DIRECTORY, f'md_knowledge_base_v{version}_part_{part_num}.json')\n",
        "            with open(part_path, 'w') as f: json.dump(current_chunk, f, indent=2)\n",
        "            print(f\"‚úÖ Created part {part_num}: {part_path}\")\n",
        "        print(f\"\\nSplitting complete. Created {part_num} parts.\")\n",
        "\n",
        "    generate_html_report(session_report, version)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        main()\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nProcess interrupted by user. Progress has been saved.\")\n",
        "    finally:\n",
        "        print(\"\\n--- Script Finished ---\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3CDC18muhe1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Markdown Knowledge Base Builder v4.8 (Free Tier Optimized)\n",
        "# @markdown Optimized for Gemini free tier: sequential processing, proper rate limiting\n",
        "\n",
        "# =============================================================================\n",
        "# 1. INSTALLATION\n",
        "# =============================================================================\n",
        "!pip install tqdm pandas google-generativeai -q\n",
        "\n",
        "import os\n",
        "import json\n",
        "import textwrap\n",
        "import time\n",
        "import hashlib\n",
        "from datetime import datetime\n",
        "import sqlite3\n",
        "import shutil\n",
        "import sys\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata, drive, auth\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "from google.api_core import exceptions as google_exceptions\n",
        "\n",
        "print(\"--- Markdown Knowledge Base Builder v4.8 (Free Tier) ---\")\n",
        "\n",
        "# Mount Google Drive\n",
        "try:\n",
        "    if not os.path.exists('/content/drive'):\n",
        "        drive.mount('/content/drive', force_remount=True)\n",
        "        print(\"‚úÖ Google Drive mounted successfully.\")\n",
        "    else:\n",
        "        print(\"‚úÖ Google Drive is already mounted.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå CRITICAL ERROR: Google Drive mount failed: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# =============================================================================\n",
        "# 2. CONFIGURATION - FREE TIER OPTIMIZED\n",
        "# =============================================================================\n",
        "DOCUMENT_DIRECTORY = '/content/drive/MyDrive/Documents/markdown'\n",
        "OUTPUT_DIRECTORY = '/content/drive/MyDrive/Documents/analyzed_markdown'\n",
        "QUARANTINE_DIRECTORY = os.path.join(OUTPUT_DIRECTORY, '_quarantine')\n",
        "DB_FILE = os.path.join(OUTPUT_DIRECTORY, 'knowledge_base_md.sqlite')\n",
        "\n",
        "# FREE TIER SETTINGS (critical for stability)\n",
        "MAX_GEMINI_RETRIES = 5\n",
        "GEMINI_RETRY_DELAY = 20  # Start with 20 seconds\n",
        "REQUEST_DELAY = 4  # 4 seconds between requests\n",
        "SUPPORTED_EXTENSIONS = ['.md']\n",
        "MAX_SPLIT_SIZE_MB = 9\n",
        "\n",
        "# =============================================================================\n",
        "# 3. DATABASE FUNCTIONS\n",
        "# =============================================================================\n",
        "def init_database():\n",
        "    with sqlite3.connect(DB_FILE) as conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS documents (\n",
        "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                filename TEXT NOT NULL,\n",
        "                file_hash TEXT NOT NULL,\n",
        "                analysis_json TEXT NOT NULL,\n",
        "                processed_at TEXT NOT NULL,\n",
        "                UNIQUE(filename, file_hash)\n",
        "            )\n",
        "        ''')\n",
        "        conn.commit()\n",
        "\n",
        "def add_to_database(filename, file_hash, analysis_result):\n",
        "    with sqlite3.connect(DB_FILE) as conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\n",
        "            \"INSERT OR REPLACE INTO documents (filename, file_hash, analysis_json, processed_at) VALUES (?, ?, ?, ?)\",\n",
        "            (filename, file_hash, json.dumps(analysis_result), analysis_result['processedAt'])\n",
        "        )\n",
        "        conn.commit()\n",
        "\n",
        "def is_file_in_database(filename, file_hash):\n",
        "    with sqlite3.connect(DB_FILE) as conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT 1 FROM documents WHERE filename = ? AND file_hash = ?\", (filename, file_hash))\n",
        "        return cursor.fetchone() is not None\n",
        "\n",
        "def get_all_from_database():\n",
        "    with sqlite3.connect(DB_FILE) as conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT analysis_json FROM documents\")\n",
        "        return [json.loads(row[0]) for row in cursor.fetchall()]\n",
        "\n",
        "def get_last_n_filenames(n=5):\n",
        "    with sqlite3.connect(DB_FILE) as conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT filename FROM documents ORDER BY id DESC LIMIT ?\", (n,))\n",
        "        return [row[0] for row in cursor.fetchall()]\n",
        "\n",
        "# =============================================================================\n",
        "# 4. HELPER FUNCTIONS\n",
        "# =============================================================================\n",
        "def get_file_hash(filepath):\n",
        "    hasher = hashlib.md5()\n",
        "    try:\n",
        "        with open(filepath, 'rb') as f:\n",
        "            while chunk := f.read(8192):\n",
        "                hasher.update(chunk)\n",
        "        return hasher.hexdigest()\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def get_file_content_as_text(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            return f.read()\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def find_supported_files_recursive(directory):\n",
        "    print(f\"\\n--- Scanning for {', '.join(SUPPORTED_EXTENSIONS)} files ---\")\n",
        "    found_files = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if os.path.splitext(file)[1].lower() in SUPPORTED_EXTENSIONS:\n",
        "                found_files.append(os.path.join(root, file))\n",
        "    print(f\"Found {len(found_files)} total supported files.\")\n",
        "    return sorted(found_files)\n",
        "\n",
        "def analyze_with_gemini_with_retries(prompt, filename, model):\n",
        "    \"\"\"Free tier optimized with exponential backoff\"\"\"\n",
        "    current_delay = GEMINI_RETRY_DELAY\n",
        "\n",
        "    for attempt in range(MAX_GEMINI_RETRIES):\n",
        "        try:\n",
        "            response = model.generate_content(\n",
        "                prompt,\n",
        "                request_options={'timeout': 600}\n",
        "            )\n",
        "            cleaned_response = response.text.strip()\n",
        "\n",
        "            # Remove code block markers\n",
        "            if cleaned_response.startswith('```json'):\n",
        "                cleaned_response = cleaned_response[7:-3].strip()\n",
        "            elif cleaned_response.startswith('```'):\n",
        "                cleaned_response = cleaned_response[3:-3].strip()\n",
        "\n",
        "            if not cleaned_response:\n",
        "                print(f\"  ‚ö†Ô∏è  Empty response for '{filename}'\")\n",
        "                return None\n",
        "\n",
        "            return json.loads(cleaned_response)\n",
        "\n",
        "        except google_exceptions.ResourceExhausted:\n",
        "            if attempt < MAX_GEMINI_RETRIES - 1:\n",
        "                print(f\"  ‚ö†Ô∏è  Rate limit hit for '{filename}' (Attempt {attempt + 1}/{MAX_GEMINI_RETRIES})\")\n",
        "                print(f\"  ‚è≥ Waiting {current_delay}s...\")\n",
        "                time.sleep(current_delay)\n",
        "                current_delay *= 2  # Exponential backoff\n",
        "            else:\n",
        "                print(f\"  ‚ùå Rate limit exceeded after {MAX_GEMINI_RETRIES} attempts: {filename}\")\n",
        "                return None\n",
        "\n",
        "        except google_exceptions.ServiceUnavailable:\n",
        "            if attempt < MAX_GEMINI_RETRIES - 1:\n",
        "                print(f\"  ‚ö†Ô∏è  Service unavailable for '{filename}' (Attempt {attempt + 1}/{MAX_GEMINI_RETRIES})\")\n",
        "                print(f\"  ‚è≥ Waiting {current_delay}s...\")\n",
        "                time.sleep(current_delay)\n",
        "                current_delay *= 1.5\n",
        "            else:\n",
        "                print(f\"  ‚ùå Service unavailable after {MAX_GEMINI_RETRIES} attempts: {filename}\")\n",
        "                return None\n",
        "\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"  ‚ùå Invalid JSON for '{filename}': {str(e)[:100]}\")\n",
        "            return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå Unexpected error for '{filename}': {type(e).__name__}\")\n",
        "            if attempt < MAX_GEMINI_RETRIES - 1:\n",
        "                time.sleep(current_delay)\n",
        "                current_delay *= 1.5\n",
        "            else:\n",
        "                return None\n",
        "\n",
        "    return None\n",
        "\n",
        "# =============================================================================\n",
        "# 5. PROCESSING LOGIC\n",
        "# =============================================================================\n",
        "def create_archival_prompt(doc_text_snippet, filename, knowledge_summary):\n",
        "    prompt = textwrap.dedent(f\"\"\"\n",
        "        You are an expert archivist AI. Analyze this document and create a structured JSON record.\n",
        "        Provide ONLY valid JSON. If information is unavailable, state \"Information not available in document\".\n",
        "\n",
        "        DOCUMENT: {filename}\n",
        "        CONTEXT: {knowledge_summary or \"First document\"}\n",
        "\n",
        "        TEXT:\n",
        "        ---\n",
        "        {doc_text_snippet}\n",
        "        ---\n",
        "\n",
        "        Required JSON:\n",
        "        {{\n",
        "          \"fileName\": \"{filename}\",\n",
        "          \"fileType\": \"{os.path.splitext(filename)[1]}\",\n",
        "          \"provenance\": \"Who created this? For what purpose?\",\n",
        "          \"originalOrder\": \"How is it structured?\",\n",
        "          \"primaryValue\": \"What purpose does it serve?\",\n",
        "          \"secondaryValue\": \"What research value does it hold?\",\n",
        "          \"significance\": \"Does it document key decisions or events?\",\n",
        "          \"uniqueness\": \"Is this information available elsewhere?\",\n",
        "          \"usability\": \"Is it well-organized and accessible?\",\n",
        "          \"context\": \"How does it relate to other files?\",\n",
        "          \"intrinsicValue\": \"Does the original form add value?\",\n",
        "          \"summary\": \"One-paragraph summary of core content.\"\n",
        "        }}\n",
        "    \"\"\")\n",
        "    return prompt\n",
        "\n",
        "def process_document(file_path, model):\n",
        "    \"\"\"Sequential processing with rate limiting\"\"\"\n",
        "    filename = os.path.basename(file_path)\n",
        "\n",
        "    try:\n",
        "        document_text = get_file_content_as_text(file_path)\n",
        "        if not document_text:\n",
        "            return None, \"Failed to extract text\"\n",
        "\n",
        "        # Limit snippet size\n",
        "        max_chars = 12000  # Smaller to reduce token usage\n",
        "        snippet = document_text[:max_chars]\n",
        "        if len(document_text) > max_chars:\n",
        "            snippet += \"\\n[... content truncated ...]\"\n",
        "\n",
        "        last_files = get_last_n_filenames(3)  # Reduced from 5\n",
        "        knowledge_summary = \"; \".join(last_files) if last_files else \"First document\"\n",
        "\n",
        "        prompt = create_archival_prompt(snippet, filename, knowledge_summary)\n",
        "        analysis_result = analyze_with_gemini_with_retries(prompt, filename, model)\n",
        "\n",
        "        if not analysis_result:\n",
        "            return None, \"Gemini analysis failed\"\n",
        "\n",
        "        analysis_result['rawText'] = document_text\n",
        "        analysis_result['filePath'] = file_path\n",
        "        analysis_result['processedAt'] = datetime.now().isoformat()\n",
        "        return analysis_result, \"Success\"\n",
        "\n",
        "    except Exception as exc:\n",
        "        print(f\"  ‚ùå Critical error processing {filename}: {exc}\")\n",
        "        return None, f\"Error: {exc}\"\n",
        "\n",
        "def generate_html_report(report_data, version):\n",
        "    df = pd.DataFrame(report_data).reindex(columns=['File', 'Status', 'Details'])\n",
        "    html = df.to_html(index=False, justify='left', border=0, classes='table table-striped')\n",
        "    html_template = f\"\"\"\n",
        "    <html><head><title>Processing Report</title><style>\n",
        "        body {{ font-family: sans-serif; margin: 2em; background-color: #f9f9f9; }}\n",
        "        h1 {{ color: #1a1a1a; }}\n",
        "        table {{ width: 100%; border-collapse: collapse; box-shadow: 0 2px 3px rgba(0,0,0,0.1); }}\n",
        "        th, td {{ padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }}\n",
        "        th {{ background-color: #4CAF50; color: white; }}\n",
        "    </style></head><body>\n",
        "        <h1>Knowledge Base Processing Report v{version}</h1>\n",
        "        <p><strong>Generated:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
        "        {html}\n",
        "    </body></html>\"\"\"\n",
        "    report_path = os.path.join(OUTPUT_DIRECTORY, f'_report_v{version}.html')\n",
        "    with open(report_path, 'w') as f:\n",
        "        f.write(html_template)\n",
        "    print(f\"üìÑ Report saved: {report_path}\")\n",
        "\n",
        "def main():\n",
        "    print(\"\\nüöÄ Starting Knowledge Base Generation (Free Tier Mode)\")\n",
        "\n",
        "    try:\n",
        "        print(\"--- Verifying API Key ---\")\n",
        "        API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "        if not API_KEY:\n",
        "            print(\"\\n‚ùå CRITICAL: 'GOOGLE_API_KEY' not found in Colab Secrets.\")\n",
        "            print(\"Go to: üîë icon (left sidebar) > Add Secret > Name: GOOGLE_API_KEY\")\n",
        "            return\n",
        "        print(\"‚úÖ API Key loaded\")\n",
        "        genai.configure(api_key=API_KEY)\n",
        "\n",
        "        for dir_path in [OUTPUT_DIRECTORY, QUARANTINE_DIRECTORY]:\n",
        "            if not os.path.exists(dir_path):\n",
        "                os.makedirs(dir_path)\n",
        "\n",
        "        auth.authenticate_user()\n",
        "        # Use stable model - better for free tier\n",
        "        model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Setup error: {e}\")\n",
        "        return\n",
        "\n",
        "    init_database()\n",
        "    all_files = find_supported_files_recursive(DOCUMENT_DIRECTORY)\n",
        "\n",
        "    if not all_files:\n",
        "        print(f\"\\n‚ö†Ô∏è  No .md files found in: {DOCUMENT_DIRECTORY}\")\n",
        "        return\n",
        "\n",
        "    session_report, files_to_process = [], []\n",
        "\n",
        "    print(\"\\n--- Checking cache ---\")\n",
        "    for fp in tqdm(all_files, desc=\"Verifying Files\"):\n",
        "        filename, file_hash = os.path.basename(fp), get_file_hash(fp)\n",
        "        if not file_hash or is_file_in_database(filename, file_hash):\n",
        "            session_report.append({\"File\": filename, \"Status\": \"Skipped\", \"Details\": \"Already processed\"})\n",
        "            continue\n",
        "        files_to_process.append(fp)\n",
        "\n",
        "    print(f\"\\nüìù {len(files_to_process)} new files to process\")\n",
        "\n",
        "    if not files_to_process:\n",
        "        print(\"‚úÖ All files already processed!\")\n",
        "        return\n",
        "\n",
        "    version = datetime.now().strftime('%Y%m%d%H%M%S')\n",
        "    print(f\"\\n--- Processing (Version: {version}) ---\")\n",
        "    print(f\"‚è±Ô∏è  Estimated time: ~{len(files_to_process) * 8 / 60:.1f} minutes\")\n",
        "\n",
        "    # SEQUENTIAL processing for free tier\n",
        "    for i, filepath in enumerate(tqdm(files_to_process, desc=\"Analyzing\")):\n",
        "        filename = os.path.basename(filepath)\n",
        "\n",
        "        try:\n",
        "            result, status = process_document(filepath, model)\n",
        "\n",
        "            if result:\n",
        "                file_hash = get_file_hash(filepath)\n",
        "                add_to_database(filename, file_hash, result)\n",
        "                session_report.append({\"File\": filename, \"Status\": \"‚úÖ Success\", \"Details\": \"Added to database\"})\n",
        "            else:\n",
        "                raise Exception(status)\n",
        "\n",
        "        except Exception as exc:\n",
        "            session_report.append({\"File\": filename, \"Status\": \"‚ùå Failed\", \"Details\": str(exc)[:100]})\n",
        "            # Move to quarantine\n",
        "            try:\n",
        "                shutil.move(filepath, os.path.join(QUARANTINE_DIRECTORY, filename))\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Rate limiting between requests (critical for free tier)\n",
        "        if i < len(files_to_process) - 1:\n",
        "            time.sleep(REQUEST_DELAY)\n",
        "\n",
        "    print(\"\\n--- Finalizing ---\")\n",
        "    knowledge_base = get_all_from_database()\n",
        "    final_save_path = os.path.join(OUTPUT_DIRECTORY, f'md_knowledge_base_v{version}.json')\n",
        "\n",
        "    with open(final_save_path, 'w') as f:\n",
        "        json.dump(knowledge_base, f, indent=2)\n",
        "\n",
        "    print(f\"\\nüéâ COMPLETE!\")\n",
        "    print(f\"üìä Total documents: {len(knowledge_base)}\")\n",
        "    print(f\"‚úÖ Saved to: {final_save_path}\")\n",
        "\n",
        "    # Split if needed\n",
        "    if os.path.getsize(final_save_path) > MAX_SPLIT_SIZE_MB * 1024 * 1024:\n",
        "        print(f\"\\n--- Splitting (Max: {MAX_SPLIT_SIZE_MB}MB) ---\")\n",
        "        with open(final_save_path, 'r') as f:\n",
        "            full_data = json.load(f)\n",
        "\n",
        "        part_num, current_chunk, current_size = 1, [], 0\n",
        "\n",
        "        for item in full_data:\n",
        "            item_size = len(json.dumps(item).encode('utf-8'))\n",
        "\n",
        "            if current_size + item_size > MAX_SPLIT_SIZE_MB * 1024 * 1024 and current_chunk:\n",
        "                part_path = os.path.join(OUTPUT_DIRECTORY, f'md_kb_v{version}_part{part_num}.json')\n",
        "                with open(part_path, 'w') as f:\n",
        "                    json.dump(current_chunk, f, indent=2)\n",
        "                print(f\"‚úÖ Part {part_num}: {part_path}\")\n",
        "                part_num += 1\n",
        "                current_chunk, current_size = [item], item_size\n",
        "            else:\n",
        "                current_chunk.append(item)\n",
        "                current_size += item_size\n",
        "\n",
        "        if current_chunk:\n",
        "            part_path = os.path.join(OUTPUT_DIRECTORY, f'md_kb_v{version}_part{part_num}.json')\n",
        "            with open(part_path, 'w') as f:\n",
        "                json.dump(current_chunk, f, indent=2)\n",
        "            print(f\"‚úÖ Part {part_num}: {part_path}\")\n",
        "\n",
        "    generate_html_report(session_report, version)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        main()\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n‚ö†Ô∏è  Interrupted by user. Progress saved.\")\n",
        "    finally:\n",
        "        print(\"\\n--- Finished ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637,
          "referenced_widgets": [
            "3367a90af54640c4b4ed2904650bac05",
            "12c2b48525b541baa0a01de8f5464842",
            "68c268ea365c469cbf833b537abaa7e5",
            "96a9874ec8914ed8badec22c4fa133e7",
            "5c7966ea1fba4bd5b97b97d03de13bb5",
            "4c40482deb6b4060a7ac0952ec6c4c4c",
            "f46b486d92ee493fb96429b4cfe4db09",
            "170fed4349964c7e8bebf7090d6976f6",
            "2b3064f5756e4e67bf29e49fae5caffe",
            "7b1787b39ae94d908fe97b76b53f10c8",
            "eea66352353b4eff9a6bc82a547e5b2b",
            "ab457581c1d14139a80749240390eaba",
            "fa779d4abd344b1196b70822dff00085",
            "fbc3ff63dfe74d3891eb335715e14a90",
            "aaea040883814893bc677de6d0837c2f",
            "0aad19b1e82549999c53a68cee82dd9e",
            "62999bde65e24688b1ec79d566670b20",
            "e85229766c1548e7a88d4703128c72c8",
            "a8349b33fd94466f8bc1d1202a2d6cc3",
            "982b2a751a844025ac2646c5e73bcf8e",
            "645e831a1edb4fd6ab87d05e5cd3acd5",
            "8c99d9ac695c4c0d81a4ae9de4fa9e70"
          ]
        },
        "cellView": "form",
        "id": "Zve5PXaei_ee",
        "outputId": "2cb41fc3-2425-430f-b05c-21beb6e31f28"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Markdown Knowledge Base Builder v4.8 (Free Tier) ---\n",
            "Mounted at /content/drive\n",
            "‚úÖ Google Drive mounted successfully.\n",
            "\n",
            "üöÄ Starting Knowledge Base Generation (Free Tier Mode)\n",
            "--- Verifying API Key ---\n",
            "‚úÖ API Key loaded\n",
            "\n",
            "--- Scanning for .md files ---\n",
            "Found 301 total supported files.\n",
            "\n",
            "--- Checking cache ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Verifying Files:   0%|          | 0/301 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3367a90af54640c4b4ed2904650bac05"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìù 293 new files to process\n",
            "\n",
            "--- Processing (Version: 20251002183946) ---\n",
            "‚è±Ô∏è  Estimated time: ~39.1 minutes\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Analyzing:   0%|          | 0/293 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab457581c1d14139a80749240390eaba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ‚ùå Invalid JSON for 'blueprint_for_a_gpt_powered_redditor_design_deployment_and_ethical_interaction.md': Expecting ',' delimiter: line 4 column 328 (char 449)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 331.26ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ‚ùå Unexpected error for 'mammoth_cave_wikibot_option.md': TooManyRequests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 230.56ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ‚ùå Unexpected error for 'mammoth_cave_wikibot_option.md': TooManyRequests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 254.47ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ‚ùå Unexpected error for 'metadata_strategy_research_report_refined.md': TooManyRequests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 255.13ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ‚ùå Unexpected error for 'monetizing_local_website_staged_plan.md': TooManyRequests\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 255.19ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ‚ùå Unexpected error for 'monetizing_local_website_staged_plan.md': TooManyRequests\n",
            "\n",
            "‚ö†Ô∏è  Interrupted by user. Progress saved.\n",
            "\n",
            "--- Finished ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyyboOTbMdL-",
        "outputId": "d55c7d7c-d0fe-4c40-8092-48f160f2e5c3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3367a90af54640c4b4ed2904650bac05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12c2b48525b541baa0a01de8f5464842",
              "IPY_MODEL_68c268ea365c469cbf833b537abaa7e5",
              "IPY_MODEL_96a9874ec8914ed8badec22c4fa133e7"
            ],
            "layout": "IPY_MODEL_5c7966ea1fba4bd5b97b97d03de13bb5"
          }
        },
        "12c2b48525b541baa0a01de8f5464842": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c40482deb6b4060a7ac0952ec6c4c4c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f46b486d92ee493fb96429b4cfe4db09",
            "value": "Verifying‚ÄáFiles:‚Äá100%"
          }
        },
        "68c268ea365c469cbf833b537abaa7e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_170fed4349964c7e8bebf7090d6976f6",
            "max": 301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b3064f5756e4e67bf29e49fae5caffe",
            "value": 301
          }
        },
        "96a9874ec8914ed8badec22c4fa133e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b1787b39ae94d908fe97b76b53f10c8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_eea66352353b4eff9a6bc82a547e5b2b",
            "value": "‚Äá301/301‚Äá[00:06&lt;00:00,‚Äá69.72it/s]"
          }
        },
        "5c7966ea1fba4bd5b97b97d03de13bb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c40482deb6b4060a7ac0952ec6c4c4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f46b486d92ee493fb96429b4cfe4db09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "170fed4349964c7e8bebf7090d6976f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b3064f5756e4e67bf29e49fae5caffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b1787b39ae94d908fe97b76b53f10c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eea66352353b4eff9a6bc82a547e5b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab457581c1d14139a80749240390eaba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa779d4abd344b1196b70822dff00085",
              "IPY_MODEL_fbc3ff63dfe74d3891eb335715e14a90",
              "IPY_MODEL_aaea040883814893bc677de6d0837c2f"
            ],
            "layout": "IPY_MODEL_0aad19b1e82549999c53a68cee82dd9e"
          }
        },
        "fa779d4abd344b1196b70822dff00085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62999bde65e24688b1ec79d566670b20",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e85229766c1548e7a88d4703128c72c8",
            "value": "Analyzing:‚Äá‚Äá74%"
          }
        },
        "fbc3ff63dfe74d3891eb335715e14a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8349b33fd94466f8bc1d1202a2d6cc3",
            "max": 293,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_982b2a751a844025ac2646c5e73bcf8e",
            "value": 217
          }
        },
        "aaea040883814893bc677de6d0837c2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_645e831a1edb4fd6ab87d05e5cd3acd5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8c99d9ac695c4c0d81a4ae9de4fa9e70",
            "value": "‚Äá217/293‚Äá[1:21:28&lt;38:18,‚Äá30.24s/it]"
          }
        },
        "0aad19b1e82549999c53a68cee82dd9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62999bde65e24688b1ec79d566670b20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e85229766c1548e7a88d4703128c72c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8349b33fd94466f8bc1d1202a2d6cc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "982b2a751a844025ac2646c5e73bcf8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "645e831a1edb4fd6ab87d05e5cd3acd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c99d9ac695c4c0d81a4ae9de4fa9e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}